from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint


def load_model():
    llm = HuggingFaceEndpoint(
        repo_id='meta-llama/Llama-3.2-3B-Instruct',
        task='text-generation',
    )
    return ChatHuggingFace(llm=llm)
# create the model
model=load_model()

# human message : Are those message which send by user 
# Ai message : Are those message which are generated by AI model
# system message : Are those message which are used to set the behavior of the model

messages= [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content="tell me about langchain."),
    
]
result=model.invoke(messages)

messages.append(AIMessage(content=result.content))
print(messages)